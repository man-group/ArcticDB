import pandas as pd
import numpy as np
import pytest
from arcticdb.util.hypothesis import (
    date,
    dataframe,
    use_of_function_scoped_fixtures_in_hypothesis_checked,
    DataframeStrategyIndexType,
)
from arcticdb.version_store._store import MergeStrategy
from hypothesis import strategies as st, given, settings, HealthCheck
from typing import List, Tuple, Optional

from arcticdb.util.test import assert_frame_equal, merge

DTYPES = ["uint32", "int64", "float", "object", "datetime64[ns]", "bool"]
COL_NAMES = [f"{dtype}_col" for dtype in DTYPES]
# Intentionally keep some pre-epoch dates in the interval. Some C++ had issues with dates before epoch in the past.
MIN_DATE = np.datetime64("1960-01-01")
MAX_DATE = np.datetime64("2025-01-01")


@st.composite
def ordered_dataframe_list(
    draw, column_names, column_dtypes, min_date=MIN_DATE, max_date=MAX_DATE
) -> List[pd.DataFrame]:
    index_ranges = sorted(draw(st.lists(date(min_date=min_date, max_date=max_date, unit="s"), min_size=2)))
    return [
        draw(dataframe(column_names, column_dtypes, index_ranges[i], index_ranges[i + 1]))
        for i in range(len(index_ranges) - 1)
    ]


@st.composite
def source_for_merge(
    draw, target: pd.DataFrame, min_date=MIN_DATE, max_date=MAX_DATE, on: List[str] = None
) -> pd.DataFrame:

    index_type = (
        DataframeStrategyIndexType.DATETIME
        if isinstance(target.index, pd.DatetimeIndex)
        else DataframeStrategyIndexType.ROWRANGE
    )
    # Generate the base source dataframe. If only draw is used, it would be highly likely to get matching rows between
    # the source and the target.
    assert target.index.name == "index"
    source = draw(dataframe(target.columns, target.dtypes, min_date, max_date, index_type=index_type))

    # Generate some rows that are going to match the target dataframe on the specified columns. First, find all unique
    # values in the on columns. Then randomly pick some of them without repetitions because one source row must not
    # match more than one target row.
    on = [] if on is None else on
    drop_duplicates_on = on + (["index"] if index_type == DataframeStrategyIndexType.DATETIME else [])
    target_with_no_duplicates = target[~target.reset_index().duplicated(subset=drop_duplicates_on, keep="first").values]
    matched = target_with_no_duplicates.iloc[
        draw(st.lists(st.integers(0, len(target_with_no_duplicates) - 1), max_size=len(source)))
    ]
    if len(matched) == 0:
        if index_type == DataframeStrategyIndexType.DATETIME:
            return source
        else:
            res = source[~source.reset_index().duplicated(subset=drop_duplicates_on, keep="first").values]
            res.index = pd.RangeIndex(len(res))
            res.index.name = "index"
            return res
    # Set the first len(matched) rows of the source dataframe to the matched rows. Set only the columns that are in
    # the "on" parameter to ensure a match will happen. Leave the other values as they are (generated by draw) so that
    # they produce new values in the columns that are not in "on" case of an update. Doing this may reorder the source,
    # thus it must be sorted in the end.
    for column in on:
        source.iloc[: len(matched), source.columns.get_loc(column)] = matched[column]
    if index_type == DataframeStrategyIndexType.DATETIME:
        source.index = matched.index.append(source.index[len(matched) :])
        source.sort_index(inplace=True)
    else:
        source.index = pd.RangeIndex(len(source))
    source.index.name = "index"
    return source[~source.reset_index().duplicated(subset=drop_duplicates_on, keep="first").values]


@st.composite
def merge_arguments(
    draw,
    column_names,
    column_dtypes,
    min_date=MIN_DATE,
    max_date=MAX_DATE,
    index_type=DataframeStrategyIndexType.DATETIME,
) -> Tuple[List[pd.DataFrame], pd.DataFrame, List[str]]:

    if index_type == DataframeStrategyIndexType.DATETIME:
        target_list = draw(ordered_dataframe_list(column_names, column_dtypes, min_date, max_date))
        target = pd.concat(target_list)
        on_columns_min_size = 0
    else:
        target_list = [draw(dataframe(column_names, column_dtypes, min_date, max_date, index_type=index_type))]
        target = target_list[0]
        on_columns_min_size = 1
    on = draw(st.lists(st.sampled_from(COL_NAMES), unique=True, min_size=on_columns_min_size))
    source = draw(source_for_merge(target, on=on))
    return target_list, source, on


@use_of_function_scoped_fixtures_in_hypothesis_checked
@given(merge_args=merge_arguments(COL_NAMES, DTYPES), on=st.lists(st.sampled_from(COL_NAMES), unique=True))
@settings(deadline=None, suppress_health_check=[HealthCheck.data_too_large])
def test_timeseries_merge_update(lmdb_version_store_v1, merge_args):
    target_list, source, on = merge_args
    lib = lmdb_version_store_v1
    symbol = "test_merge_update"
    lib.version_store.force_delete_symbol(symbol)
    for df in target_list:
        lib.append(symbol, df)
    strategy = MergeStrategy(matched="update", not_matched_by_target="do_nothing")
    lib.merge_experimental(symbol, source, strategy=strategy, on=on)
    result = lib.read(symbol).data
    expected = merge(pd.concat(target_list), source, strategy=strategy, on=on)
    assert_frame_equal(result, expected)


@use_of_function_scoped_fixtures_in_hypothesis_checked
@given(merge_args=merge_arguments(COL_NAMES, DTYPES, index_type=DataframeStrategyIndexType.ROWRANGE))
@settings(deadline=None, suppress_health_check=[HealthCheck.data_too_large])
def test_rowrange_merge_update(lmdb_version_store_v1, merge_args):
    target, source, on = merge_args
    pd.set_option("display.max_rows", None)
    pd.set_option("display.max_columns", None)
    pd.set_option("display.width", None)
    print(target)
    print(source)
    print(on)
    assert len(target) == 1
    lib = lmdb_version_store_v1
    symbol = "test_merge_update"
    lib.version_store.force_delete_symbol(symbol)
    lib.write(symbol, target[0])
    strategy = MergeStrategy(matched="update", not_matched_by_target="do_nothing")
    lib.merge_experimental(symbol, source, strategy=strategy, on=on)
    result = lib.read(symbol).data
    expected = merge(target[0], source, strategy=strategy, on=on)
    assert_frame_equal(result, expected)
