{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcticDB Recursive Normalizers Demo\n",
    "\n",
    "This notebook demonstrates the **recursive normalizers** feature in ArcticDB, which allows you to write nested data structures without having to pickle the entire object.\n",
    "\n",
    "## What are Recursive Normalizers?\n",
    "\n",
    "Recursive normalizers enable ArcticDB to:\n",
    "- Write and read nested data structures (dicts, lists, tuples) containing DataFrames and arrays\n",
    "- Store each component efficiently without pickling the entire structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arcticdb as adb\n",
    "from arcticdb.util.test import equals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Arctic instance with LMDB backend\n",
    "arctic = adb.Arctic(\"lmdb://recursive_normalizers_demo\")\n",
    "\n",
    "lib = arctic.get_library(\"demo\", create_if_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example: Writing Dict Data\n",
    "\n",
    "Let's start with a simple example of writing a dictionary containing DataFrames and arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original nested data:\n",
      "{'dataframe1':    col1 col2\n",
      "0     1    a\n",
      "1     2    b\n",
      "2     3    c, 'dataframe2':    value\n",
      "0     10\n",
      "1     20\n",
      "2     30, 'array': array([0, 1, 2, 3, 4]), 'metadata': {'description': 'Sample nested data'}}\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "df1 = pd.DataFrame({\"col1\": [1, 2, 3], \"col2\": [\"a\", \"b\", \"c\"]})\n",
    "df2 = pd.DataFrame({\"value\": [10, 20, 30]})\n",
    "array = np.arange(5)\n",
    "\n",
    "# Create nested structure\n",
    "nested_data = {\n",
    "    \"dataframe1\": df1,\n",
    "    \"dataframe2\": df2,\n",
    "    \"array\": array,\n",
    "    \"metadata\": {\"description\": \"Sample nested data\"}\n",
    "}\n",
    "\n",
    "print(\"Original nested data:\")\n",
    "print(nested_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Without Recursive Normalizers (Will Fail)\n",
    "\n",
    "By default, ArcticDB cannot write nested structures without pickling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception thrown: Data is of a type that cannot be normalized. Consider using write_pickle instead. type(data)=[<class 'dict'>]\n"
     ]
    }
   ],
   "source": [
    "# This will raise an exception, recursive_normalizers is False by default\n",
    "try:\n",
    "    lib.write(\"nested_data_fail\", nested_data)\n",
    "except Exception as e:\n",
    "    print(f\"Exception thrown: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing With Recursive Normalizers (Success)\n",
    "\n",
    "Enable recursive normalizers to write the nested structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written!\n",
      "\n",
      "Assertion passed: Read data matches original nested_data!\n"
     ]
    }
   ],
   "source": [
    "# Write with recursive normalizers enabled\n",
    "lib.write(\"nested_data_success\", nested_data, recursive_normalizers=True)\n",
    "print(\"Successfully written!\")\n",
    "\n",
    "# Read it back\n",
    "result = lib.read(\"nested_data_success\").data\n",
    "\n",
    "# Verify the data matches the original\n",
    "equals(nested_data, result)\n",
    "print(\"\\nAssertion passed: Read data matches original nested_data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Lists and Tuples\n",
    "\n",
    "Recursive normalizers also work with lists and tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List data successfully written and verified!\n"
     ]
    }
   ],
   "source": [
    "# Create list of DataFrames\n",
    "list_data = [\n",
    "    pd.DataFrame({\"a\": [1, 2, 3]}),\n",
    "    pd.DataFrame({\"b\": [4, 5, 6]}),\n",
    "    np.array([7, 8, 9])\n",
    "]\n",
    "\n",
    "lib.write(\"list_data\", list_data, recursive_normalizers=True)\n",
    "result = lib.read(\"list_data\").data\n",
    "\n",
    "# Verify the data matches\n",
    "equals(list_data, result)\n",
    "print(\"List data successfully written and verified!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple data successfully written and verified!\n"
     ]
    }
   ],
   "source": [
    "# Create tuple of mixed data\n",
    "tuple_data = (\n",
    "    np.arange(5),\n",
    "    pd.DataFrame({\"col\": [1, 2, 3]}),\n",
    "    {\"nested\": np.arange(3)}\n",
    ")\n",
    "\n",
    "lib.write(\"tuple_data\", tuple_data, recursive_normalizers=True)\n",
    "result = lib.read(\"tuple_data\").data\n",
    "\n",
    "# Verify the data matches\n",
    "equals(tuple_data, result)\n",
    "print(\"Tuple data successfully written and verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Nested Structures\n",
    "\n",
    "Recursive normalizers can handle nested structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested structure successfully written and verified!\n"
     ]
    }
   ],
   "source": [
    "# Create nested structure\n",
    "nested = {\n",
    "    \"level1\": {\n",
    "        \"level2\": {\n",
    "            \"level3\": {\n",
    "                \"dataframe\": pd.DataFrame({\"x\": [1, 2, 3]}),\n",
    "                \"array\": np.arange(10)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"another_branch\": [\n",
    "        pd.DataFrame({\"y\": [4, 5, 6]}),\n",
    "        {\"nested_dict\": np.array([7, 8, 9])}\n",
    "    ]\n",
    "}\n",
    "\n",
    "lib.write(\"nested\", nested, recursive_normalizers=True)\n",
    "result = lib.read(\"nested\").data\n",
    "\n",
    "# Verify the data matches\n",
    "equals(nested, result)\n",
    "print(\"Nested structure successfully written and verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Recursive Normalizer in Library Configuration\n",
    "You can configure recursive normalizers at the library configuration instead of specifying it for each write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Library Options\n",
    "\n",
    "You can modify an existing library's configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 13:07:07,890 INFO  [arcticdb.arctic] Set option=[ModifiableLibraryOption.RECURSIVE_NORMALIZERS] to value=[True] for Arctic=[Arctic(config=LMDB(path=/recursive_normalizers_demo))] Library=[Library(Arctic(config=LMDB(path=/recursive_normalizers_demo)), path=demo, storage=lmdb_storage)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written successfully after modifying library option and verified!\n"
     ]
    }
   ],
   "source": [
    "# Enable recursive normalizers for existing library\n",
    "from arcticdb_ext.storage import ModifiableLibraryOption\n",
    "arctic.modify_library_option(lib, ModifiableLibraryOption.RECURSIVE_NORMALIZERS, True)\n",
    "\n",
    "# Now writes will enable recursive normalizers by default\n",
    "data = {\"df\": pd.DataFrame({\"b\": [4, 5, 6]}), \"arr\": np.arange(3)}\n",
    "lib.write(\"modified_lib_write\", data)\n",
    "\n",
    "result = lib.read(\"modified_lib_write\").data\n",
    "equals(data, result)\n",
    "print(\"Data written successfully after modifying library option and verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Library\n",
    "You can also create a new library with recursive normalizers enabled by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written successfully with library option enabled and verified!\n"
     ]
    }
   ],
   "source": [
    "# Create a new library with recursive normalizers enabled by default\n",
    "lib_recursive = arctic.create_library(\"demo_recursive\", library_options=adb.LibraryOptions(recursive_normalizers=True))\n",
    "\n",
    "# Now you can write without specifying recursive_normalizers=True\n",
    "data = {\"df\": pd.DataFrame({\"a\": [1, 2, 3]}), \"arr\": np.arange(5)}\n",
    "lib_recursive.write(\"auto_recursive\", data)\n",
    "\n",
    "result = lib_recursive.read(\"auto_recursive\").data\n",
    "equals(data, result)\n",
    "print(\"Data written successfully with library option enabled and verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using write_pickle with Recursive Normalizers\n",
    "\n",
    "The `write_pickle` method can also use recursive normalizers. This is useful when you have nested structures with some components that cannot be natively normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with write: Error while normalizing symbol=mixed_fail__custom, Normalizing data by pickling has been disabled.\n",
      "Data written with write_pickle and verified! Data has been partially-pickled\n"
     ]
    }
   ],
   "source": [
    "# Custom class that cannot be natively normalized\n",
    "class CustomClass:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, CustomClass) and self.value == other.value\n",
    "\n",
    "# Data with custom class\n",
    "mixed_data = {\n",
    "    \"dataframe\": pd.DataFrame({\"a\": [1, 2, 3]}),\n",
    "    \"array\": np.arange(5),\n",
    "    \"custom\": CustomClass(42)\n",
    "}\n",
    "\n",
    "# This will fail with regular write\n",
    "try:\n",
    "    lib.write(\"mixed_fail\", mixed_data, recursive_normalizers=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error with write: {e}\")\n",
    "\n",
    "# But works with write_pickle\n",
    "lib.write_pickle(\"mixed_success\", mixed_data, recursive_normalizers=True)\n",
    "result = lib.read(\"mixed_success\").data\n",
    "\n",
    "# Verify the data matches\n",
    "equals(mixed_data, result)\n",
    "print(\"Data written with write_pickle and verified! Data has been partially-pickled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception Handling Examples\n",
    "\n",
    "Let's explore various exceptions that can occur when using recursive normalizers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ArcticUnsupportedDataTypeException\n",
    "\n",
    "This exception occurs when trying to write nested data without enabling recursive normalizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught ArcticUnsupportedDataTypeException:\n",
      "Message: Data is of a type that cannot be normalized. Consider using write_pickle instead. type(data)=[<class 'dict'>]\n",
      "\n",
      "Solution: Use recursive_normalizers=True or write_pickle\n"
     ]
    }
   ],
   "source": [
    "from arcticdb.version_store.library import ArcticUnsupportedDataTypeException\n",
    "\n",
    "data = {\"df\": pd.DataFrame({\"a\": [1, 2, 3]})}\n",
    "\n",
    "try:\n",
    "    lib.write(\"exception_test1\", data, recursive_normalizers=False)\n",
    "except ArcticUnsupportedDataTypeException as e:\n",
    "    print(\"Caught ArcticUnsupportedDataTypeException:\")\n",
    "    print(f\"Message: {str(e)}\")\n",
    "    print(\"\\nSolution: Use recursive_normalizers=True or write_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DataTooNestedException\n",
    "\n",
    "There's a limit to how deeply nested structures can be (255 levels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught DataTooNestedException:\n",
      "Message: Symbol exception_test3 cannot be recursively normalized as it contains more than 255 levels of nested dictionaries. This is a limitation of the msgpack serializer.\n",
      "\n",
      "Solution: Reduce nesting depth to 255 levels or less\n"
     ]
    }
   ],
   "source": [
    "from arcticdb.exceptions import DataTooNestedException\n",
    "\n",
    "# Create a structure that's too deeply nested (256 levels)\n",
    "def create_deep_nest(depth):\n",
    "    if depth == 0:\n",
    "        return pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "    return {\"nested\": create_deep_nest(depth - 1)}\n",
    "\n",
    "try:\n",
    "    too_deep = create_deep_nest(256)\n",
    "    lib.write(\"exception_test3\", too_deep, recursive_normalizers=True)\n",
    "except DataTooNestedException as e:\n",
    "    print(\"Caught DataTooNestedException:\")\n",
    "    print(f\"Message: {str(e)}\")\n",
    "    print(\"\\nSolution: Reduce nesting depth to 255 levels or less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SchemaException\n",
    "\n",
    "Recursive normalized data cannot be filtered. Attempting to filter such data will raise a SchemaException."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught SchemaException\n",
      "Message: E_OPERATION_NOT_SUPPORTED_WITH_RECURSIVE_NORMALIZED_DATA Cannot filter recursively normalized data\n",
      "\n",
      "Solution: Recursive normalized data cannot be filtered. Read the full data without filtering.\n",
      "Caught SchemaException again\n"
     ]
    }
   ],
   "source": [
    "from arcticdb.exceptions import SchemaException\n",
    "from arcticdb.version_store.processing import QueryBuilder\n",
    "\n",
    "# Try to filter recursively normalized data - this will fail\n",
    "try:\n",
    "    q = QueryBuilder()\n",
    "    q = q[q[\"col\"] == 0]\n",
    "    lib.read(\"nested\", query_builder=q)\n",
    "except SchemaException as e:\n",
    "    print(\"Caught SchemaException\")\n",
    "    print(f\"Message: {str(e)}\")\n",
    "    print(\"\\nSolution: Recursive normalized data cannot be filtered. Read the full data without filtering.\")\n",
    "\n",
    "try:\n",
    "    lib.head(\"nested\")\n",
    "except SchemaException as e:\n",
    "    print(\"Caught SchemaException again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Use recursive normalizers for nested structures**: When you have dictionaries or lists containing DataFrames and arrays\n",
    "2. **Configure at library level**: If you frequently write nested data, enable it at the library level\n",
    "4. **Limit nesting depth**: Keep nesting under 255 levels\n",
    "5. **Use write_pickle for mixed data**: When you have custom objects that can't be normalized\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
