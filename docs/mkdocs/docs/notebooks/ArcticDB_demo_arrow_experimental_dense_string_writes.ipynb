{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c62b62-3509-4c2b-9d6f-bc3dc0187c72",
   "metadata": {},
   "source": [
    "# ArcticDB Experimental Arrow Writing Dense String Data Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a677f71-55d8-446d-a372-8b5bb0bc7e02",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the next cut of writing pyarrow tables directly into ArcticDB. This is still an experimental feature, with both the API and behaviours subject to change in minor or patch releases, and under no circumstances should be deployed to production environments. There are still a lot of rough edges, many of which are highlighted below, that will be addressed in future releases. This cut adds support for writing string columns.\n",
    "\n",
    "### Performance-wise, writing string data in Arrow Tables is never slower than Pandas, and can be up to x2 faster depending on the table size, number of unique strings in the data, and the number of cores involved.\n",
    "\n",
    "### Please read the notebook for numeric data before this one, functionality covered there that behaves in the same way for string columns is not repeated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71d190-49c7-4d24-bea9-c27b72f5a2b6",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b93432d-a9f5-4e32-8b39-be7cdcb382eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "from ahl.mongo.mongoose import NativeMongoose\n",
    "from arcticdb import Arctic, OutputFormat, QueryBuilder, WritePayload\n",
    "from arcticdb.util.arrow import stringify_dictionary_encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55619b80-29c6-4260-8edb-13fc75b7e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic = Arctic(\"lmdb://arrow-writes-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9eefcb-1775-4e09-9044-7967de292022",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = arctic.get_library(\"test_lib\", output_format=OutputFormat.EXPERIMENTAL_ARROW, create_if_missing=True)\n",
    "lib._nvs._set_allow_arrow_input(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304f83f9-06d9-4618-94c1-ffa8eb1b8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib._nvs.version_store.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174660b5-0c46-4152-b5c3-5e49a6ec76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3ab149-8e24-4fea-b481-1dfe9e8d7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(table):\n",
    "    print(pl.from_arrow(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad28717-560b-4eee-90d0-41ca7f9ece86",
   "metadata": {},
   "source": [
    "## Write some string data of both supported string types\n",
    "\n",
    "PyArrow uses the `string` type by default. This is sufficient for use cases where the sum of the length of all of the strings in a column (without deduplication) is less than 2GB. If this is insufficient, then the `large_string` type is required, which supports total string lengths up to 8 exabytes, which is probably enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd17977-0c01-4ff3-ac04-a5c924f785a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† str       â”† str       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† these     â”† here      â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† are       â”† are       â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† some      â”† some      â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† strings   â”† more      â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "table_0 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-01\", periods=4), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"these\", \"are\", \"some\", \"strings\"], pa.string()),\n",
    "        \"strings 2\": pa.array([\"here\", \"are\", \"some\", \"more\"], pa.large_string()),\n",
    "    }\n",
    ")\n",
    "print_table(table_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff9b977-d285-4e91-bc11-d40421cdd9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VersionedItem(symbol='test', library='test_lib', data=n/a, version=0, metadata=None, host='LMDB(path=/data/team/data/arctic_native/examples/arrow-writes-demo)', timestamp=1761570730696143527)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.write(sym, table_0, index_column=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ac9451-ca9f-45d0-b40c-2d64fda01fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† cat       â”† cat       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† these     â”† here      â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† are       â”† are       â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† some      â”† some      â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† strings   â”† more      â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "received_table = lib.read(sym).data\n",
    "print_table(received_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ac286-f69f-4f04-8bd6-445b4b583c5a",
   "metadata": {},
   "source": [
    "## Note that in this release string columns are still dictionary-encoded in the output (`cat`, short for categorical in Polars). This will be fixed in a future release, but for now it means that string data read out of ArcticDB cannot be immeditely written back without a conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c600332b-1f67-47c0-8824-f9088a087331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_UNSUPPORTED_COLUMN_TYPE Dictionary-encoded Arrow data unsupported\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lib.write(sym, received_table)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a10f085-9506-4dc9-8cc9-9d126eadd906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VersionedItem(symbol='test', library='test_lib', data=n/a, version=1, metadata=None, host='LMDB(path=/data/team/data/arctic_native/examples/arrow-writes-demo)', timestamp=1761570746629560088)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_table = stringify_dictionary_encoded_columns(received_table)\n",
    "lib.write(sym, converted_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a742b-74c0-40d1-8b77-52c5820c1a89",
   "metadata": {},
   "source": [
    "## Strings in Arrow are internally represented as UTF-8, so this full character set is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734bbc9f-9d90-4ac5-8508-c822f800a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† str       â”† str       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† ğŸ”„        â”† â‚¬         â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ        â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰        â”† Ã–         â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† ğŸ™Š        â”† Ã¢         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "table_0 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-01\", periods=4), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"ğŸ”„\", \"ğŸ™ˆ\", \"ğŸ™‰\", \"ğŸ™Š\"], pa.string()),\n",
    "        \"strings 2\": pa.array([\"â‚¬\", \"Â©\", \"Ã–\", \"Ã¢\"], pa.large_string()),\n",
    "    }\n",
    ")\n",
    "print_table(table_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a89e88-857d-4a5a-8566-771d1b32161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† cat       â”† cat       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† ğŸ”„        â”† â‚¬         â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ        â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰        â”† Ã–         â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† ğŸ™Š        â”† Ã¢         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "lib.write(sym, table_0, index_column=\"timestamp\")\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9a556-e032-4d83-904f-44d908125116",
   "metadata": {},
   "source": [
    "## Append some data to this\n",
    "\n",
    "Note that the `strings 1` column now has type `large_string`, and the `strings 2` column not has type `string`, the opposite way round to in the `write` call. We store both types the same internally, and so this is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea662fa-e0a9-4147-a70a-26f44ff81d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† cat       â”† cat       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† ğŸ”„        â”† â‚¬         â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ        â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰        â”† Ã–         â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† ğŸ™Š        â”† Ã¢         â”‚\n",
      "â”‚ 2025-01-05 00:00:00 â”† even      â”† hello     â”‚\n",
      "â”‚ 2025-01-06 00:00:00 â”† more      â”† bonjour   â”‚\n",
      "â”‚ 2025-01-07 00:00:00 â”† strings   â”† gutentag  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "table_1 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-05\", periods=3), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"even\", \"more\", \"strings\"], pa.large_string()),\n",
    "        \"strings 2\": pa.array([\"hello\", \"bonjour\", \"gutentag\"], pa.string()),\n",
    "    }\n",
    ")\n",
    "lib.append(sym, table_1, index_column=\"timestamp\")\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e3ad9-250b-43f9-8fbc-865d52468db2",
   "metadata": {},
   "source": [
    "## `update` works in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f16ca2-8c5a-4f12-b027-d745c8d6900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1   â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---         â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† str         â”† str       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-04 00:00:00 â”† replacement â”† goodbye   â”‚\n",
      "â”‚ 2025-01-05 00:00:00 â”† strings     â”† au revoir â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "table_2 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-04\", periods=2), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"replacement\", \"strings\"]),\n",
    "        \"strings 2\": pa.array([\"goodbye\", \"au revoir\"]),\n",
    "    }\n",
    ")\n",
    "print_table(table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f333a719-57be-42e6-80ea-1a2b3776f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1   â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---         â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† cat         â”† cat       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† ğŸ”„          â”† â‚¬         â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ          â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰          â”† Ã–         â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† replacement â”† goodbye   â”‚\n",
      "â”‚ 2025-01-05 00:00:00 â”† strings     â”† au revoir â”‚\n",
      "â”‚ 2025-01-06 00:00:00 â”† more        â”† bonjour   â”‚\n",
      "â”‚ 2025-01-07 00:00:00 â”† strings     â”† gutentag  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "lib.update(sym, table_2, index_column=\"timestamp\")\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c899c-c311-45d8-b9f6-73219d7bffb2",
   "metadata": {},
   "source": [
    "## Writing views of data works as you would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2480d5a9-5c00-4681-83cd-c808d7aaf7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† str       â”† str       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ        â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰        â”† Ã–         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "table_view = table_0.slice(1, 2)\n",
    "print_table(table_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c99f43-0031-45cf-966c-cd2184e91ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† cat       â”† cat       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ        â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰        â”† Ã–         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "lib.write(sym, table_view)\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa86505-6df9-40d0-aee6-a974db87c7e7",
   "metadata": {},
   "source": [
    "## Staging (AKA incomplete) APIs also work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43e6699f-0629-4627-8a8c-483bfb69fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† strings 1 â”† strings 2 â”‚\n",
      "â”‚ ---                 â”† ---       â”† ---       â”‚\n",
      "â”‚ datetime[ns]        â”† cat       â”† cat       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-01-01 00:00:00 â”† ğŸ”„        â”† â‚¬         â”‚\n",
      "â”‚ 2025-01-02 00:00:00 â”† ğŸ™ˆ        â”† Â©         â”‚\n",
      "â”‚ 2025-01-03 00:00:00 â”† ğŸ™‰        â”† Ã–         â”‚\n",
      "â”‚ 2025-01-04 00:00:00 â”† ğŸ™Š        â”† Ã¢         â”‚\n",
      "â”‚ 2025-01-05 00:00:00 â”† even      â”† hello     â”‚\n",
      "â”‚ 2025-01-06 00:00:00 â”† more      â”† bonjour   â”‚\n",
      "â”‚ 2025-01-07 00:00:00 â”† strings   â”† gutentag  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to calling write with parallel=True, write with incomplete=True, or append with incomplete=True\n",
    "lib.stage(sym, table_0, index_column=\"timestamp\")\n",
    "lib.stage(sym, table_1, index_column=\"timestamp\")\n",
    "lib.finalize_staged_data(sym)\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759e8fa-1fae-41c1-9a62-c129a4d2e22d",
   "metadata": {},
   "source": [
    "# Pandas interoperability\n",
    "\n",
    "## Data written as Arrow can be read as Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6ada021-7f61-40c5-8e9c-d2c475ec278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strings 1</th>\n",
       "      <th>strings 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>ğŸ”„</td>\n",
       "      <td>â‚¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02</th>\n",
       "      <td>ğŸ™ˆ</td>\n",
       "      <td>Â©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03</th>\n",
       "      <td>ğŸ™‰</td>\n",
       "      <td>Ã–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-04</th>\n",
       "      <td>ğŸ™Š</td>\n",
       "      <td>Ã¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05</th>\n",
       "      <td>even</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06</th>\n",
       "      <td>more</td>\n",
       "      <td>bonjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>strings</td>\n",
       "      <td>gutentag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           strings 1 strings 2\n",
       "timestamp                     \n",
       "2025-01-01         ğŸ”„         â‚¬\n",
       "2025-01-02         ğŸ™ˆ         Â©\n",
       "2025-01-03         ğŸ™‰         Ã–\n",
       "2025-01-04         ğŸ™Š         Ã¢\n",
       "2025-01-05      even     hello\n",
       "2025-01-06      more   bonjour\n",
       "2025-01-07   strings  gutentag"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.read(sym, output_format=OutputFormat.PANDAS).data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrow",
   "language": "python",
   "name": "arrow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
