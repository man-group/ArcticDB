{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c62b62-3509-4c2b-9d6f-bc3dc0187c72",
   "metadata": {},
   "source": [
    "# ArcticDB Experimental Arrow Writing Dense String Data Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a677f71-55d8-446d-a372-8b5bb0bc7e02",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the next cut of writing pyarrow tables directly into ArcticDB. This is still an experimental feature, with both the API and behaviours subject to change in minor or patch releases, and under no circumstances should be deployed to production environments. There are still a lot of rough edges, many of which are highlighted below, that will be addressed in future releases. This cut adds support for writing string columns.\n",
    "\n",
    "### Performance-wise, writing string data in Arrow Tables is never slower than Pandas, and can be up to x2 faster depending on the table size, number of unique strings in the data, and the number of cores involved.\n",
    "\n",
    "### Please read the notebook for numeric data before this one, functionality covered there that behaves in the same way for string columns is not repeated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71d190-49c7-4d24-bea9-c27b72f5a2b6",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b93432d-a9f5-4e32-8b39-be7cdcb382eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "from ahl.mongo.mongoose import NativeMongoose\n",
    "from arcticdb import Arctic, OutputFormat, QueryBuilder, WritePayload\n",
    "from arcticdb.util.arrow import stringify_dictionary_encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55619b80-29c6-4260-8edb-13fc75b7e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic = Arctic(\"lmdb://arrow-writes-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9eefcb-1775-4e09-9044-7967de292022",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = arctic.get_library(\"test_lib\", output_format=OutputFormat.EXPERIMENTAL_ARROW, create_if_missing=True)\n",
    "lib._nvs._set_allow_arrow_input(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304f83f9-06d9-4618-94c1-ffa8eb1b8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib._nvs.version_store.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174660b5-0c46-4152-b5c3-5e49a6ec76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3ab149-8e24-4fea-b481-1dfe9e8d7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(table):\n",
    "    print(pl.from_arrow(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad28717-560b-4eee-90d0-41ca7f9ece86",
   "metadata": {},
   "source": [
    "## Write some string data of both supported string types\n",
    "\n",
    "PyArrow uses the `string` type by default. This is sufficient for use cases where the sum of the length of all of the strings in a column (without deduplication) is less than 2GB. If this is insufficient, then the `large_string` type is required, which supports total string lengths up to 8 exabytes, which is probably enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd17977-0c01-4ff3-ac04-a5c924f785a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ str       ┆ str       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ these     ┆ here      │\n",
      "│ 2025-01-02 00:00:00 ┆ are       ┆ are       │\n",
      "│ 2025-01-03 00:00:00 ┆ some      ┆ some      │\n",
      "│ 2025-01-04 00:00:00 ┆ strings   ┆ more      │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "table_0 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-01\", periods=4), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"these\", \"are\", \"some\", \"strings\"], pa.string()),\n",
    "        \"strings 2\": pa.array([\"here\", \"are\", \"some\", \"more\"], pa.large_string()),\n",
    "    }\n",
    ")\n",
    "print_table(table_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff9b977-d285-4e91-bc11-d40421cdd9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VersionedItem(symbol='test', library='test_lib', data=n/a, version=0, metadata=None, host='LMDB(path=/data/team/data/arctic_native/examples/arrow-writes-demo)', timestamp=1761570730696143527)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.write(sym, table_0, index_column=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ac9451-ca9f-45d0-b40c-2d64fda01fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ cat       ┆ cat       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ these     ┆ here      │\n",
      "│ 2025-01-02 00:00:00 ┆ are       ┆ are       │\n",
      "│ 2025-01-03 00:00:00 ┆ some      ┆ some      │\n",
      "│ 2025-01-04 00:00:00 ┆ strings   ┆ more      │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "received_table = lib.read(sym).data\n",
    "print_table(received_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ac286-f69f-4f04-8bd6-445b4b583c5a",
   "metadata": {},
   "source": [
    "## Note that in this release string columns are still dictionary-encoded in the output (`cat`, short for categorical in Polars). This will be fixed in a future release, but for now it means that string data read out of ArcticDB cannot be immeditely written back without a conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c600332b-1f67-47c0-8824-f9088a087331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_UNSUPPORTED_COLUMN_TYPE Dictionary-encoded Arrow data unsupported\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lib.write(sym, received_table)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a10f085-9506-4dc9-8cc9-9d126eadd906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VersionedItem(symbol='test', library='test_lib', data=n/a, version=1, metadata=None, host='LMDB(path=/data/team/data/arctic_native/examples/arrow-writes-demo)', timestamp=1761570746629560088)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_table = stringify_dictionary_encoded_columns(received_table)\n",
    "lib.write(sym, converted_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a742b-74c0-40d1-8b77-52c5820c1a89",
   "metadata": {},
   "source": [
    "## Strings in Arrow are internally represented as UTF-8, so this full character set is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734bbc9f-9d90-4ac5-8508-c822f800a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ str       ┆ str       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ 🔄        ┆ €         │\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈        ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉        ┆ Ö         │\n",
      "│ 2025-01-04 00:00:00 ┆ 🙊        ┆ â         │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "table_0 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-01\", periods=4), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"🔄\", \"🙈\", \"🙉\", \"🙊\"], pa.string()),\n",
    "        \"strings 2\": pa.array([\"€\", \"©\", \"Ö\", \"â\"], pa.large_string()),\n",
    "    }\n",
    ")\n",
    "print_table(table_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a89e88-857d-4a5a-8566-771d1b32161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ cat       ┆ cat       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ 🔄        ┆ €         │\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈        ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉        ┆ Ö         │\n",
      "│ 2025-01-04 00:00:00 ┆ 🙊        ┆ â         │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "lib.write(sym, table_0, index_column=\"timestamp\")\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9a556-e032-4d83-904f-44d908125116",
   "metadata": {},
   "source": [
    "## Append some data to this\n",
    "\n",
    "Note that the `strings 1` column now has type `large_string`, and the `strings 2` column not has type `string`, the opposite way round to in the `write` call. We store both types the same internally, and so this is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea662fa-e0a9-4147-a70a-26f44ff81d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ cat       ┆ cat       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ 🔄        ┆ €         │\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈        ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉        ┆ Ö         │\n",
      "│ 2025-01-04 00:00:00 ┆ 🙊        ┆ â         │\n",
      "│ 2025-01-05 00:00:00 ┆ even      ┆ hello     │\n",
      "│ 2025-01-06 00:00:00 ┆ more      ┆ bonjour   │\n",
      "│ 2025-01-07 00:00:00 ┆ strings   ┆ gutentag  │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "table_1 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-05\", periods=3), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"even\", \"more\", \"strings\"], pa.large_string()),\n",
    "        \"strings 2\": pa.array([\"hello\", \"bonjour\", \"gutentag\"], pa.string()),\n",
    "    }\n",
    ")\n",
    "lib.append(sym, table_1, index_column=\"timestamp\")\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e3ad9-250b-43f9-8fbc-865d52468db2",
   "metadata": {},
   "source": [
    "## `update` works in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f16ca2-8c5a-4f12-b027-d745c8d6900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌─────────────────────┬─────────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1   ┆ strings 2 │\n",
      "│ ---                 ┆ ---         ┆ ---       │\n",
      "│ datetime[ns]        ┆ str         ┆ str       │\n",
      "╞═════════════════════╪═════════════╪═══════════╡\n",
      "│ 2025-01-04 00:00:00 ┆ replacement ┆ goodbye   │\n",
      "│ 2025-01-05 00:00:00 ┆ strings     ┆ au revoir │\n",
      "└─────────────────────┴─────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "table_2 = pa.table(\n",
    "    {\n",
    "        \"timestamp\": pa.Array.from_pandas(pd.date_range(\"2025-01-04\", periods=2), type=pa.timestamp(\"ns\")),\n",
    "        \"strings 1\": pa.array([\"replacement\", \"strings\"]),\n",
    "        \"strings 2\": pa.array([\"goodbye\", \"au revoir\"]),\n",
    "    }\n",
    ")\n",
    "print_table(table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f333a719-57be-42e6-80ea-1a2b3776f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "┌─────────────────────┬─────────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1   ┆ strings 2 │\n",
      "│ ---                 ┆ ---         ┆ ---       │\n",
      "│ datetime[ns]        ┆ cat         ┆ cat       │\n",
      "╞═════════════════════╪═════════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ 🔄          ┆ €         │\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈          ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉          ┆ Ö         │\n",
      "│ 2025-01-04 00:00:00 ┆ replacement ┆ goodbye   │\n",
      "│ 2025-01-05 00:00:00 ┆ strings     ┆ au revoir │\n",
      "│ 2025-01-06 00:00:00 ┆ more        ┆ bonjour   │\n",
      "│ 2025-01-07 00:00:00 ┆ strings     ┆ gutentag  │\n",
      "└─────────────────────┴─────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "lib.update(sym, table_2, index_column=\"timestamp\")\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c899c-c311-45d8-b9f6-73219d7bffb2",
   "metadata": {},
   "source": [
    "## Writing views of data works as you would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2480d5a9-5c00-4681-83cd-c808d7aaf7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ str       ┆ str       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈        ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉        ┆ Ö         │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "table_view = table_0.slice(1, 2)\n",
    "print_table(table_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c99f43-0031-45cf-966c-cd2184e91ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ cat       ┆ cat       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈        ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉        ┆ Ö         │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "lib.write(sym, table_view)\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa86505-6df9-40d0-aee6-a974db87c7e7",
   "metadata": {},
   "source": [
    "## Staging (AKA incomplete) APIs also work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43e6699f-0629-4627-8a8c-483bfb69fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "┌─────────────────────┬───────────┬───────────┐\n",
      "│ timestamp           ┆ strings 1 ┆ strings 2 │\n",
      "│ ---                 ┆ ---       ┆ ---       │\n",
      "│ datetime[ns]        ┆ cat       ┆ cat       │\n",
      "╞═════════════════════╪═══════════╪═══════════╡\n",
      "│ 2025-01-01 00:00:00 ┆ 🔄        ┆ €         │\n",
      "│ 2025-01-02 00:00:00 ┆ 🙈        ┆ ©         │\n",
      "│ 2025-01-03 00:00:00 ┆ 🙉        ┆ Ö         │\n",
      "│ 2025-01-04 00:00:00 ┆ 🙊        ┆ â         │\n",
      "│ 2025-01-05 00:00:00 ┆ even      ┆ hello     │\n",
      "│ 2025-01-06 00:00:00 ┆ more      ┆ bonjour   │\n",
      "│ 2025-01-07 00:00:00 ┆ strings   ┆ gutentag  │\n",
      "└─────────────────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to calling write with parallel=True, write with incomplete=True, or append with incomplete=True\n",
    "lib.stage(sym, table_0, index_column=\"timestamp\")\n",
    "lib.stage(sym, table_1, index_column=\"timestamp\")\n",
    "lib.finalize_staged_data(sym)\n",
    "print_table(lib.read(sym).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759e8fa-1fae-41c1-9a62-c129a4d2e22d",
   "metadata": {},
   "source": [
    "# Pandas interoperability\n",
    "\n",
    "## Data written as Arrow can be read as Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6ada021-7f61-40c5-8e9c-d2c475ec278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strings 1</th>\n",
       "      <th>strings 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>🔄</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02</th>\n",
       "      <td>🙈</td>\n",
       "      <td>©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03</th>\n",
       "      <td>🙉</td>\n",
       "      <td>Ö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-04</th>\n",
       "      <td>🙊</td>\n",
       "      <td>â</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05</th>\n",
       "      <td>even</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06</th>\n",
       "      <td>more</td>\n",
       "      <td>bonjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>strings</td>\n",
       "      <td>gutentag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           strings 1 strings 2\n",
       "timestamp                     \n",
       "2025-01-01         🔄         €\n",
       "2025-01-02         🙈         ©\n",
       "2025-01-03         🙉         Ö\n",
       "2025-01-04         🙊         â\n",
       "2025-01-05      even     hello\n",
       "2025-01-06      more   bonjour\n",
       "2025-01-07   strings  gutentag"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.read(sym, output_format=OutputFormat.PANDAS).data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrow",
   "language": "python",
   "name": "arrow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
