name: Build with analysis tools
on:
  workflow_dispatch:
    inputs:
      run:
        type: boolean

  push:
    branches:
        - "analysis_workflow"
jobs:
  cibw_docker_image:
    uses: ./.github/workflows/cibw_docker_image.yml
    permissions: {packages: write}
    with:
        cibuildwheel_ver: "2.12.1"
        force_update: false

  code_coverage:
    needs: [cibw_docker_image]  
    runs-on: "ubuntu-latest"
    container:
        image: ${{needs.cibw_docker_image.outputs.tag}}
    services:
      mongodb:
        image: mongo:4.4
        ports:
          - 27017:27017
    env:
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}} # Setting this env var enables the caching
      VCPKG_NUGET_USER: ${{secrets.VCPKG_NUGET_USER || github.repository_owner}}
      VCPKG_NUGET_TOKEN: ${{secrets.VCPKG_NUGET_TOKEN || secrets.GITHUB_TOKEN}}
      VCPKG_MAN_NUGET_USER: ${{secrets.VCPKG_MAN_NUGET_USER}} # For forks to download pre-compiled dependencies from the Man repo
      VCPKG_MAN_NUGET_TOKEN: ${{secrets.VCPKG_MAN_NUGET_TOKEN}}
      CMAKE_C_COMPILER_LAUNCHER: sccache
      CMAKE_CXX_COMPILER_LAUNCHER: sccache
      ARCTIC_CMAKE_PRESET: linux-debug
      CIBW_ENVIRONMENT_PASS_LINUX: SCCACHE_GHA_VERSION ACTIONS_CACHE_URL ACTIONS_RUNTIME_TOKEN VCPKG_INSTALLATION_ROOT
        VCPKG_BINARY_SOURCES VCPKG_NUGET_USER VCPKG_NUGET_TOKEN VCPKG_MAN_NUGET_USER VCPKG_MAN_NUGET_TOKEN
        CMAKE_C_COMPILER_LAUNCHER CMAKE_CXX_COMPILER_LAUNCHER CMAKE_BUILD_PARALLEL_LEVEL ARCTIC_CMAKE_PRESET
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v1
        id: cpu-cores

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.3
        with:
          version: "v0.4.0"

      - name: Extra envs
        run: |
          . build_tooling/vcpkg_caching.sh # Linux follower needs another call in CIBW
          echo -e "VCPKG_BINARY_SOURCES=$VCPKG_BINARY_SOURCES
          VCPKG_ROOT=$PLATFORM_VCPKG_ROOT" | tee -a $GITHUB_ENV
          cmake -P cpp/CMake/CpuCount.cmake | sed 's/^-- //' | tee -a $GITHUB_ENV
        env:
          CMAKE_BUILD_PARALLEL_LEVEL: ${{vars.CMAKE_BUILD_PARALLEL_LEVEL}}

      - name: Prepare C++ compilation env
        run: . build_tooling/prep_cpp_build.sh 
      
      - name: CMake compile
        uses: lukka/run-cmake@v10
        with:
          cmakeListsTxtPath: ${{github.workspace}}/cpp/CMakeLists.txt
          configurePreset: ${{env.ARCTIC_CMAKE_PRESET}}
          buildPreset: ${{env.ARCTIC_CMAKE_PRESET}}
        env:
          ARCTICDB_CODE_COVERAGE_BUILD: 1

      # - name: CPP build dir
      #   run: |
      #     cd cpp/out/linux-debug-build/arcticdb
      #     ls -al .
        
      - name: Run C++ Tests
        shell: bash -l {0}
        run: |
          cd cpp/out/linux-debug-build/
          make -j ${{ steps.cpu-cores.outputs.count }} arcticdb_rapidcheck_tests
          make -j ${{ steps.cpu-cores.outputs.count }} test_unit_arcticdb
          ctest

      - name: Select Python 3.6
        run: echo /opt/python/cp36-cp36m/bin >> $GITHUB_PATH

      - name: Discover test directory names
        # There are so few nonreg tests, run them in the hypothesis runner
        run: find python/tests/* -maxdepth 0 -type d ! -regex '.*\(__pycache__\|util\|nonreg\)' -printf '"%f",' |
              sed 's/^/test_dirs=[/ ; s/"hypothesis"/"{hypothesis,nonreg}"/ ; s/,$/]/' | tee -a $GITHUB_ENV

      - name: Test with pytest
        shell: bash -l {0}
        run: |
          yum install nodejs npm -y
          npm config set strict-ssl false
          npm install -g azurite
          /opt/python/cp36-cp36m/bin/python -m pip install --upgrade pip
          /opt/python/cp36-cp36m/bin/python -m pip install pycparser six cffi urllib3 python-dateutil PyJWT jmespath idna cryptography charset-normalizer certifi requests py pluggy path oauthlib MarkupSafe iniconfig dataclasses botocore attrs Werkzeug termcolor s3transfer requests-oauthlib pytz pytest protobuf portalocker path.py numpy msal mock Jinja2 itsdangerous isodate grpcio execnet decorator contextlib2 click azure-core xxhash xmltodict sortedcontainers retry responses pyyaml pytest-shutil pytest-fixture-config psutil prometheus-client pandas msrest msgpack msal-extensions grpcio-tools future flask colorama boto3 pytest-timeout pytest-server-fixtures pytest-cpp pymongo moto hypothesis flask-cors azure-storage-blob azure-identity coverage pytest-xdist
          /opt/python/cp36-cp36m/bin/python -m grpc_tools.protoc -Icpp/proto --python_out=./python cpp/proto/arcticc/pb2/*.proto
          cd python
          export MAN_ARCTICDB_USE_ARCTICDB=True
          ln -s ../cpp/out/linux-debug-build/arcticdb/arcticdb_ext.cpython-36m-x86_64-linux-gnu.so
          cp ../build_tooling/parallel_test.sh .
          ./parallel_test.sh tests/${{env.test_dirs}}
        env:
          TEST_OUTPUT_DIR: ${{runner.temp}}
          # Use the Mongo created in the service container above to test against
          CI_MONGO_HOST: mongodb

      - name: Gcovr manually pre-pytest
        shell: bash -l {0}
        run: |
          cd cpp/out/linux-debug-build/
          python3 -m pip install gcovr
          mkdir coverage
          python3 -m gcovr --txt --html-details coverage/coverage.html -e vcpkg_installed/ -e proto/ -e ../../third_party -e ../../arcticdb/util/test/ -r ../.. --exclude-throw-branches --exclude-unreachable-branches -u --exclude-function-lines
          zip -r coverage.zip coverage/

      - name: Upload Coverage
        uses: actions/upload-artifact@v3
        with:
          name: coverage-artifact
          path: cpp/out/linux-debug-build/coverage.zip
