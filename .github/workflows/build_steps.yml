name: __build_steps
on:
  workflow_call:
    inputs:
      job_type:          {required: true, type: string, description: Selects the steps to enable}
      cmake_preset_type: {required: true, type: string, description: release/debug}
      matrix:            {required: true, type: string, description: JSON string to feed into the matrix}
      cibw_image_tag:    {required: false, type: string, description: Linux only. As built by cibw_docker_image.yml workflow}
      cibw_version:      {required: false, type: string, description: Follower only. Must match the cibw_image_tag}
      cibw_build:        {required: false, type: string, description: Follower only.}
      python3:           {default: -1, type: number, description: Python 3 minor version}
env:
  python_impl_name: ${{inputs.python3 > 0 && format('cp3{0}', inputs.python3) || 'default'}}
jobs:
  compile:
    strategy:
      matrix:
        # Declaring the dummy fields here to aid the Github Actions linting in VSCode and to provide documentation
        os: [0] # Decouples the steps from any distro version changes
        distro: [0]
        cmake_preset_prefix: [0]
        envs: [0]
        build_dir: [0] # Must be an absolute path
        symbols: [0] # Glob for symbol symbol files. Used for including in follower builds and exclusion on others.
        do_not_archive: [0]
        exclude:
            - os: 0
        include:
            - ${{fromJSON(inputs.matrix)}}

    runs-on: ${{fromJson(matrix.distro)}}
    container: ${{ (matrix.os == 'linux' && inputs.job_type != 'follower') && inputs.cibw_image_tag || null}}
    env:
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}} # Setting this env var enables the caching
      VCPKG_NUGET_USER: ${{secrets.VCPKG_NUGET_USER || github.repository_owner}}
      VCPKG_NUGET_TOKEN: ${{secrets.VCPKG_NUGET_TOKEN || secrets.GITHUB_TOKEN}}
      VCPKG_MAN_NUGET_USER: ${{secrets.VCPKG_MAN_NUGET_USER}} # For forks to download pre-compiled dependencies from the Man repo
      VCPKG_MAN_NUGET_TOKEN: ${{secrets.VCPKG_MAN_NUGET_TOKEN}}
      CMAKE_C_COMPILER_LAUNCHER: sccache
      CMAKE_CXX_COMPILER_LAUNCHER: sccache
      ARCTIC_CMAKE_PRESET: ${{matrix.cmake_preset_prefix}}-${{inputs.cmake_preset_type}}
      ARCTICDB_BUILD_DIR: ${{matrix.build_dir}}
      CIBW_ENVIRONMENT_PASS_LINUX: SCCACHE_GHA_VERSION ACTIONS_CACHE_URL ACTIONS_RUNTIME_TOKEN VCPKG_INSTALLATION_ROOT
        VCPKG_BINARY_SOURCES VCPKG_NUGET_USER VCPKG_NUGET_TOKEN VCPKG_MAN_NUGET_USER VCPKG_MAN_NUGET_TOKEN
        CMAKE_C_COMPILER_LAUNCHER CMAKE_CXX_COMPILER_LAUNCHER CMAKE_BUILD_PARALLEL_LEVEL ARCTIC_CMAKE_PRESET
        ARCTICDB_BUILD_DIR TEST_OUTPUT_DIR
      ARCTICDB_DEBUG_FIND_PYTHON: ${{vars.ARCTICDB_DEBUG_FIND_PYTHON}}
    defaults:
      run: {shell: bash}
    steps:
      - name: Checkout
        uses: actions/checkout@v3.3.0
        with:
          submodules: recursive # Just in case a dep has its own third-party deps

      - name: Extra envs
        run: |
          . build_tooling/vcpkg_caching.sh # Linux follower needs another call in CIBW
          echo -e "VCPKG_BINARY_SOURCES=$VCPKG_BINARY_SOURCES\n${{matrix.envs || ''}}" | tee -a $GITHUB_ENV
          cmake -P cpp/CMake/CpuCount.cmake | sed 's/^-- //' | tee -a $GITHUB_ENV
        env:
          CMAKE_BUILD_PARALLEL_LEVEL: ${{vars.CMAKE_BUILD_PARALLEL_LEVEL}}

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.3
        with:
          version: "v0.4.0"

      - name: Windows Pagefile
        if: matrix.os == 'windows'
        uses: al-cheb/configure-pagefile-action@v1.3
        with:
          minimum-size: 2GB
          maximum-size: 6GB
          disk-root: "D:"  # This is also the checkout directory. Total size 12GB.
        continue-on-error: true

      - name: Enable Windows compiler commands
        if: matrix.os == 'windows'
        uses: ilammy/msvc-dev-cmd@v1.12.1

      # ========================= Leader steps =========================
      - name: Prepare C++ compilation env
        if: inputs.job_type != 'follower'
        run: . build_tooling/prep_cpp_build.sh # Also applies to Windows

      - name: CMake compile
        if: inputs.job_type != 'follower'
        uses: lukka/run-cmake@v10
        with:
          cmakeListsTxtPath: ${{github.workspace}}/cpp/CMakeLists.txt
          configurePreset: ${{env.ARCTIC_CMAKE_PRESET}}
          configurePresetAdditionalArgs: "['-DVCPKG_INSTALL_OPTIONS=--clean-after-build']"
          buildPreset: ${{env.ARCTIC_CMAKE_PRESET}}

      - name: Compile C++ tests
        if: inputs.job_type == 'cpp-tests'
        run: cd cpp; cmake --build --preset $ARCTIC_CMAKE_PRESET --target install

      - name: C++ Rapidcheck
        if: inputs.job_type == 'cpp-tests'
        run: cpp/out/install/arcticdb_rapidcheck_tests

      - name: C++ unit tests
        if: inputs.job_type == 'cpp-tests'
        run: |
          cd cpp/out
          install/test_unit_arcticdb --gtest_output=json:test_unit_arcticdb.json \
            --gtest_filter=-TestNfsBackedStorage.*:TestS3Storage.* || true
          [[ $(jq '.tests' test_unit_arcticdb.json) -gt 0 ]]
          [[ $(jq '.failures' test_unit_arcticdb.json) -eq 0 ]]
          [[ $(jq '.errors' test_unit_arcticdb.json) -eq 0 ]]
        env:
          ARCTICDB_memory_loglevel: INFO

      # ========================= Follower (CIBW) steps =========================
      - name: Get CIBuildWheel image & metadata
        if: inputs.job_type == 'follower' && matrix.os == 'linux'
        run: |
            docker login ghcr.io -u token -p "${{secrets.GITHUB_TOKEN}}"
            docker pull "${{inputs.cibw_image_tag}}"
            docker inspect --type=image "${{inputs.cibw_image_tag}}" \
              --format='manylinux_image={{index .Config.Labels "io.arcticdb.base"}}' | tee -a $GITHUB_ENV

      - name: Build wheel
        if: inputs.job_type == 'follower'
        run: pipx run cibuildwheel==${{inputs.cibw_version}}
        env:
          CIBW_BUILD: ${{inputs.cibw_build}}
          CIBW_MANYLINUX_X86_64_IMAGE: ${{inputs.cibw_image_tag}}

      - name: Store wheel artifact
        if: inputs.job_type == 'follower'
        uses: actions/upload-artifact@v3
        with:
          name: wheel-${{inputs.cibw_build}}
          path: wheelhouse/*.whl

      - name: Discover test directory names
        if: inputs.job_type == 'follower'
        # There are so few nonreg tests, run them in the hypothesis runner
        run: find python/tests/* -maxdepth 0 -type d ! -regex '.*\(__pycache__\|util\|nonreg\)' -printf '"%f",' |
              sed 's/^/test_dirs=[/ ; s/"hypothesis"/"{hypothesis,nonreg}"/ ; s/,$/]/' | tee -a $GITHUB_ENV

      # ========================= Common =========================
      - name: Disk usage
        if: always()
        run: du -m . "${{matrix.build_dir}}" | sort -n | tail -n 100 ; df -h
        continue-on-error: true

      - name: Make build directory readable for archiving
        if: inputs.job_type == 'follower' && matrix.os == 'linux' && always()
        run: sudo chown -R $UID ${{matrix.build_dir}}

      - name: Archive build metadata
        uses: actions/upload-artifact@v3
        if: always()
        env:
          _exclusion: "\n!${{matrix.build_dir}}/**/"
        with:
          name: build-metadata-${{inputs.job_type}}-${{matrix.os}}-${{env.python_impl_name}}
          retention-days: ${{inputs.job_type == 'cpp-tests' && 7 || 90}}
          # On Windows, exclusions like "!**/*.ext" are prefixed with a drive letter (D:\) of the current working dir
          # before matching. This breaks since we moved the build_dir to C:. Work around by templating exclusions:
          path: ${{matrix.build_dir}}/*-build
            ${{env._exclusion}}${{inputs.job_type == 'follower' && 'nofile' || matrix.symbols}}
            ${{env._exclusion}}${{join(matrix.do_not_archive, env._exclusion)}}

    outputs:
      manylinux_image: ${{env.manylinux_image}}
      test_dirs: ${{env.test_dirs}}

  python_tests:
    if: inputs.job_type == 'follower'
    needs: [compile]
    strategy:
      fail-fast: false
      matrix:
        type: ${{fromJSON(vars.TEST_DIRS_OVERRIDE || needs.compile.outputs.test_dirs)}}
        include:
          - ${{fromJSON(inputs.matrix)}}
    name: ${{matrix.type}}
    runs-on: ${{fromJson(matrix.pytest_distro || matrix.distro)}}
    container: ${{matrix.os == 'linux' && needs.compile.outputs.manylinux_image || null}}
    defaults:
      run: {shell: bash}
    steps:
      - name: Checkout
        uses: actions/checkout@v3.3.0

      - name: Get wheel artifact
        uses: actions/download-artifact@v3
        with:
          name: wheel-${{inputs.cibw_build}}
          path: ${{runner.temp}}

      - name: Select Python (Linux)
        if: matrix.os == 'linux'
        run: echo /opt/python/${{env.python_impl_name}}*/bin >> $GITHUB_PATH

      - name: Select Python (Windows)
        if: matrix.os == 'windows'
        uses: actions/setup-python@v4
        with:
          python-version: "3.${{inputs.python3}}"

      - name: Windows Pagefile
        if: matrix.os == 'windows'
        uses: al-cheb/configure-pagefile-action@v1.3
        with:
          minimum-size: 2GB
          maximum-size: 8GB
          disk-root: "D:"  # This is also the checkout directory. Total size 12GB.
        continue-on-error: true

      - name: Install the wheel and dependencies
        run: |
          cmake -P cpp/CMake/CpuCount.cmake | sed 's/^-- //' | tee -a $GITHUB_ENV
          python -V
          cd "$RUNNER_TEMP" # Works for Windows-style paths as well
          python -m pip install --force-reinstall *${{env.python_impl_name}}*.whl
          python -m pip install arcticdb[Testing] pytest-split
          python -m pip uninstall -y pytest-cpp || true # No longer works on 3.6
          echo -e "${{matrix.envs || ''}}" | tee -a $GITHUB_ENV
          if [[ -n "$MSYSTEM" ]] ; then
            echo "LOCALAPPDATA=$LOCALAPPDATA" | tee -a $GITHUB_ENV
            MSYS_NO_PATHCONV=1 reg.exe ADD 'HKLM\SOFTWARE\Microsoft\Windows\Windows Error Reporting\LocalDumps'
            cd "/proc/registry/HKEY_LOCAL_MACHINE/SOFTWARE/Microsoft"
            find "Windows NT/CurrentVersion/AeDebug" "Windows/Windows Error Reporting/LocalDumps" \
              -type f -print -exec xxd -c 64 '{}' \; || true
          fi
          ${{vars.EXTRA_TEST_PREPARE_CMD || ''}}
        env:
          CMAKE_BUILD_PARALLEL_LEVEL: ${{vars.CMAKE_BUILD_PARALLEL_LEVEL}}

      - name: Run test
        run: build_tooling/parallel_test.sh tests/${{matrix.type}}
        env:
          TEST_OUTPUT_DIR: ${{runner.temp}}

      - name: Collect crash dumps (Windows)
        if: matrix.os == 'windows' && failure()
        uses: actions/upload-artifact@v3
        with:
          name: crashdump-${{matrix.os}}-${{env.python_impl_name}}-${{matrix.type}}
          path: ${{env.LOCALAPPDATA}}/CrashDumps/

      - name: Disk usage
        if: always()
        run: set +e ; du -m . "${PARALLEL_TEST_ROOT:-/tmp/parallel_test}" | sort -n | tail -n 100 ; df -h
        continue-on-error: true

      - name: Upload the logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: pytest-${{matrix.os}}-${{env.python_impl_name}}-${{matrix.type}}
          path: |
            ${{runner.temp}}/*test*
