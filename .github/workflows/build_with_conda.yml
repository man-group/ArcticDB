name: Build with conda

permissions:
  contents: read

run-name: Building ${{github.ref_name}} on ${{github.event_name}} by ${{github.actor}}

concurrency:
  group: ${{github.ref}}-${{github.workflow}}
  cancel-in-progress: true

on:
  push:
    branches:
      - master
  # For Pull-Requests, this runs the CI on merge commit
  # of HEAD with the target branch instead on HEAD, allowing
  # testing against potential new states which might have
  # been introduced in the target branch last commits.
  # See: https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#pull_request
  pull_request:

  workflow_dispatch:
    inputs:
      run_on_arm_mac:
        description: 'Run on arm macos'
        type: boolean
        required: false
        default: false
      run_cpp_tests:
        description: 'Run C++ tests'
        type: boolean
        required: true
        default: true
      persistent_storage:
        description: "Run against what persistent storage type? (no is LMDB/default)"
        type: choice
        options:
          - 'no'
          - 'AWS_S3'
          - 'GCPXML'
          - 'AZURE'
        default: 'no'
      debug_enabled:
        type: boolean
        description: 'Run the build with debugging enabled'
        required: false
        default: false
      run_enable_logging:
        description: 'Enabled debug logging'
        type: boolean
        required: false
        default: false
      run_commandline:
        description: 'Run custom commandline before tests, Like: export ARCTICDB_STORAGE_AZURE=1; ....'
        type: string
        required: false
        default: ""
      run_custom_pytest_command:
        description: '*Run custom pytest command, instead of standard(Note: curdir is project root), or pass additional arguments to default command'
        type: string
        required: false
        default: ""

jobs:

  compile_linux:
    name: Compile (linux_64)
    if: |
      always() &&
      !cancelled()
    runs-on: ubuntu-22.04
    env:
      ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v6.0.1
        # Do not use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false # Time-consuming but doesn't save that much space (4GB)
          docker-images: false  # We're using docker images we don't want to clear

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          environment-name: arcticdb
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'

      - name: Build ArcticDB with conda (ARCTICDB_USING_CONDA=1)
        run: |
          # Protocol buffers compilation require not using build isolation.
          # We should always retry due to unstable nature of connections and environments
          python -m pip install --no-build-isolation --no-deps --retries 3 --timeout 400 -v -e .
        env:
          ARCTICDB_USING_CONDA: 1
          ARCTICDB_BUILD_CPP_TESTS: 1

      - name: Archive build artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: build-linux
          retention-days: 7
          path: |
            cpp/out/linux-conda-release-build/
            python/arcticdb_ext*
            python/**/*.so
            python/**/*.pyd

  compile_macos:
    name: Compile (osx_arm64)
    if: |
      always() &&
      !cancelled()
    runs-on: macos-14
    env:
      ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v6.0.1
        # Do not use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          environment-name: arcticdb
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'

      - name: Build ArcticDB with conda (ARCTICDB_USING_CONDA=1)
        run: |
          # Protocol buffers compilation require not using build isolation.
          # We should always retry due to unstable nature of connections and environments
          python -m pip install --no-build-isolation --no-deps --retries 3 --timeout 400 -v -e .
        env:
          ARCTICDB_USING_CONDA: 1
          ARCTICDB_BUILD_CPP_TESTS: 1

      - name: Archive build artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: build-macos
          retention-days: 7
          path: |
            cpp/out/macos-conda-release-build/
            python/arcticdb_ext*
            python/**/*.so
            python/**/*.pyd

  cpp_tests_linux:
    name: C++ Tests (linux_64)
    if: |
      always() &&
      !cancelled() &&
      (inputs.run_cpp_tests == true || github.event_name != 'workflow_dispatch')
    needs: [compile_linux]
    runs-on: ubuntu-22.04
    env:
      ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v6.0.1
        # Do not use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false # Time-consuming but doesn't save that much space (4GB)
          docker-images: false  # We're using docker images we don't want to clear

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-linux
          path: .

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          environment-name: arcticdb
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'

      - name: Configure C++ Tests (linux_64)
        run: |
          cd cpp
          cmake --preset linux-conda-release -DTEST=ON
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Build C++ Tests (linux_64)
        run: |
          cd cpp
          cmake --build --preset linux-conda-release --target arcticdb_rapidcheck_tests -j ${{ steps.cpu-cores.outputs.count }}
          cmake --build --preset linux-conda-release --target test_unit_arcticdb -j ${{ steps.cpu-cores.outputs.count }}
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Run C++ Tests (linux_64)
        run: |
          cd cpp/out/linux-conda-release-build/
          ctest --output-on-failure
        env:
          ARCTICDB_USING_CONDA: 1

  cpp_tests_macos:
    name: C++ Tests (osx_arm64)
    if: |
      always() &&
      !cancelled() &&
      (inputs.run_cpp_tests == true || github.event_name != 'workflow_dispatch')
    needs: [compile_macos]
    runs-on: macos-14
    env:
      ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v6.0.1
        # Do not use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-macos
          path: .

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          environment-name: arcticdb
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'

      - name: Configure C++ Tests (osx_arm64)
        run: |
          cd cpp
          cmake --preset macos-conda-release -DTEST=ON
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Build C++ Tests (osx_arm64)
        run: |
          cd cpp
          cmake --build --preset macos-conda-release --target arcticdb_rapidcheck_tests -j ${{ steps.cpu-cores.outputs.count }}
          cmake --build --preset macos-conda-release --target test_unit_arcticdb -j ${{ steps.cpu-cores.outputs.count }}
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Run C++ Tests (osx_arm64)
        run: |
          cd cpp/out/macos-conda-release-build/
          ctest --output-on-failure
        env:
          ARCTICDB_USING_CONDA: 1

  python_tests_linux:
    name: Python Tests (linux_64)
    if: |
      always() &&
      !cancelled()
    needs: [compile_linux]
    runs-on: ubuntu-22.04
    env:
      ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    services:
      mongodb:
        image: mongo:4.4
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false # Time-consuming but doesn't save that much space (4GB)
          docker-images: false  # We're using docker images we don't want to clear

      - uses: actions/checkout@v6.0.1
        # Do not use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-linux
          path: .

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          environment-name: arcticdb
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'

      - name: Install ArcticDB from artifacts
        run: |
          # Protocol buffers compilation require not using build isolation.
          # We should always retry due to unstable nature of connections and environments
          # This reuses the build artifacts from the compile_linux step and make ArcticDB available for testing.
          python -m pip install --no-build-isolation --no-deps --retries 3 --timeout 400 -v -e .
        env:
          ARCTICDB_USING_CONDA: 1

      # Note: mongo tests are skipped in the macos workflow
      - name: Install MongoDB
        uses: ./.github/actions/install_mongodb

      - name: Install npm # Linux github runner image does not come with npm
        uses: actions/setup-node@v6.1.0
        with:
          node-version: '24'

      - name: Install Azurite
        uses: nick-fields/retry@v3
        with:
          # We should always retry due to unstable nature of connections and environments
          timeout_minutes: 10
          max_attempts: 3
          command: npm install -g azurite

      - name: Check no arcticdb file depend on tests package
        run: |
          build_tooling/checks.sh

      - name: Set persistent storage variables
        # Should be executed for all persistent storages but not for LMDB
        if: ${{ inputs.persistent_storage != 'no' }}
        uses: ./.github/actions/set_persistent_storage_env_vars
        with:
          aws_access_key: "${{ secrets.AWS_S3_ACCESS_KEY }}"
          aws_secret_key: "${{ secrets.AWS_S3_SECRET_KEY }}"
          gcp_access_key: "${{ secrets.GCP_S3_ACCESS_KEY }}"
          gcp_secret_key: "${{ secrets.GCP_S3_SECRET_KEY }}"
          azure_container: "githubblob" # DEFAULT BUCKET FOR AZURE
          azure_connection_string: "${{ secrets.AZURE_CONNECTION_STRING }}"
          persistent_storage: ${{ inputs.persistent_storage || 'no' }}

      - name: Set ArcticDB Debug Logging
        if: ${{ inputs.run_enable_logging }}
        uses: ./.github/actions/enable_logging

      - name: Setup tmate session
        uses: mxschmitt/action-tmate@v3
        if: ${{ inputs.debug_enabled }}

      - name: Install pytest-repeat
        run: |
          python -m pip --retries 3 --timeout 180 install pytest-repeat

      - name: Test with pytest
        run: |
          # find ssl directory where cacerts are (for Azure)
          openssl version -d
          # list file descriptors and other limits of the runner
          ulimit -a
          echo "Run commandline: $COMMANDLINE"
          eval "$COMMANDLINE"
          export ARCTICDB_WARN_ON_WRITING_EMPTY_DATAFRAME=0
          if [[ "$(echo "$ARCTICDB_PYTEST_ARGS" | xargs)" == pytest* ]]; then
            python -m pip install pytest-repeat setuptools wheel
            python setup.py protoc --build-lib python
            echo "Run custom pytest command: $ARCTICDB_PYTEST_ARGS"
            eval "$ARCTICDB_PYTEST_ARGS"
          else
            build_tooling/parallel_test.sh tests
          fi
        env:
          ARCTICDB_USING_CONDA: 1
          COMMANDLINE: ${{ inputs.run_commandline }}
          # Use the Mongo created in the service container above to test against
          CI_MONGO_HOST: mongodb
          HYPOTHESIS_PROFILE: ci_linux
          PYTEST_XDIST_MODE: -n logical --dist worksteal
          ARCTICDB_PYTEST_ARGS: ${{ inputs.run_custom_pytest_command }}
          TEST_OUTPUT_DIR: ${{runner.temp}}
          STORAGE_TYPE: ${{ inputs.persistent_storage == 'no' && 'LMDB' || inputs.persistent_storage }}
          group: conda-linux
          NODE_OPTIONS: --openssl-legacy-provider

  python_tests_macos:
    name: Python Tests (osx_arm64)
    if: |
      always() &&
      !cancelled()
    needs: [compile_macos]
    runs-on: macos-14
    env:
      ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - uses: actions/checkout@v6.0.1
        # Do not use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-macos
          path: .

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          environment-name: arcticdb
          init-shell: >-
            bash
          cache-environment: true
          post-cleanup: 'all'

      - name: Install ArcticDB from artifacts
        run: |
          # Protocol buffers compilation require not using build isolation.
          # We should always retry due to unstable nature of connections and environments
          # This reuses the build artifacts from the compile_macos step and make ArcticDB available for testing.
          python -m pip install --no-build-isolation --no-deps --retries 3 --timeout 400 -v -e .
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Install npm
        uses: actions/setup-node@v6.1.0
        with:
          node-version: '24'

      - name: Install Azurite
        uses: nick-fields/retry@v3
        with:
          # We should always retry due to unstable nature of connections and environments
          timeout_minutes: 10
          max_attempts: 3
          command: npm install -g azurite

      - name: Check no arcticdb file depend on tests package
        run: |
          build_tooling/checks.sh

      - name: Set persistent storage variables
        # Should be executed for all persistent storages but not for LMDB
        if: ${{ inputs.persistent_storage != 'no' }}
        uses: ./.github/actions/set_persistent_storage_env_vars
        with:
          aws_access_key: "${{ secrets.AWS_S3_ACCESS_KEY }}"
          aws_secret_key: "${{ secrets.AWS_S3_SECRET_KEY }}"
          gcp_access_key: "${{ secrets.GCP_S3_ACCESS_KEY }}"
          gcp_secret_key: "${{ secrets.GCP_S3_SECRET_KEY }}"
          azure_container: "githubblob" # DEFAULT BUCKET FOR AZURE
          azure_connection_string: "${{ secrets.AZURE_CONNECTION_STRING }}"
          persistent_storage: ${{ inputs.persistent_storage  || 'no' }}

      - name: Set ArcticDB Debug Logging
        if: ${{ inputs.run_enable_logging }}
        uses: ./.github/actions/enable_logging

      - name: Setup tmate session
        uses: mxschmitt/action-tmate@v3
        if: ${{ inputs.debug_enabled }}

      - name: Install pytest-repeat
        run: |
          python -m pip --retries 3 --timeout 180 install pytest-repeat

      - name: Test with pytest
        run: |
          # find ssl directory where cacerts are (for Azure)
          openssl version -d
          # list file descriptors and other limits of the runner
          ulimit -a
          echo "Run commandline: $COMMANDLINE"
          eval "$COMMANDLINE"
          export ARCTICDB_WARN_ON_WRITING_EMPTY_DATAFRAME=0
          if [[ "$(echo "$ARCTICDB_PYTEST_ARGS" | xargs)" == pytest* ]]; then
            python -m pip install pytest-repeat setuptools wheel
            python setup.py protoc --build-lib python
            echo "Run custom pytest command: $ARCTICDB_PYTEST_ARGS"
            eval "$ARCTICDB_PYTEST_ARGS"
          else
            build_tooling/parallel_test.sh tests
          fi
        env:
          ARCTICDB_USING_CONDA: 1
          COMMANDLINE: ${{ inputs.run_commandline }}
          HYPOTHESIS_PROFILE: ci_macos
          PYTEST_XDIST_MODE: -n logical --dist worksteal
          ARCTICDB_PYTEST_ARGS: ${{ inputs.run_custom_pytest_command }}
          TEST_OUTPUT_DIR: ${{runner.temp}}
          STORAGE_TYPE: ${{ inputs.persistent_storage == 'no' && 'LMDB' || inputs.persistent_storage }}
          group: conda-macos
          NODE_OPTIONS: --openssl-legacy-provider

  compile_windows:
    name: Compile (win_64)
    if: |
      always() &&
      !cancelled()
    runs-on: windows-latest
    env:
      ACTIONS_ALLOW_UNSECURE_COMMANDS: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    steps:
      - uses: actions/checkout@v6.0.1
        # DONT use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Get number of CPU cores
        uses: SimenB/github-actions-cpu-cores@v2.0.0
        id: cpu-cores

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          init-shell: bash cmd.exe
          cache-environment: true
          post-cleanup: 'all'

      - name: Build ArcticDB with conda (ARCTICDB_USING_CONDA=1)
        shell: cmd /C call {0}
        run: |
          REM Some `CMAKE_*` variables (in particular CMAKE_GENERATOR_{PLATFORM,TOOLSET}) are set by mamba / micromamba / conda
          REM when the environment is activated.
          REM See: https://github.com/conda-forge/vc-feedstock/blob/c6bb71096319ff21ac8b75f7d91183be914c3d6b/recipe/activate.bat#L87-L131
          REM The values which are chosen prevent Ninja to be used as a generator with MSVC.
          REM We override those values so that we can.
          set CMAKE_GENERATOR_PLATFORM=
          set CMAKE_GENERATOR_TOOLSET=
          REM Protocol buffers compilation require not using build isolation.
          REM We should always retry due to unstable nature of connections and environments
          python -m pip install --no-build-isolation --no-deps --retries 3 --timeout 400 -v -e .
        env:
          ARCTICDB_USING_CONDA: 1
          ARCTICDB_BUILD_CPP_TESTS: 1
          ARCTIC_CMAKE_PRESET: windows-cl-conda-release

      - name: Archive build artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: build-windows
          retention-days: 7
          path: |
            cpp/out/windows-cl-conda-release-build/
            python/arcticdb_ext*
            python/**/*.so
            python/**/*.pyd

  cpp_tests_windows:
    name: C++ Tests (win_64)
    if: |
      always() &&
      !cancelled() &&
      (inputs.run_cpp_tests == true || github.event_name != 'workflow_dispatch')
    needs: [compile_windows]
    runs-on: windows-latest
    env:
      ACTIONS_ALLOW_UNSECURE_COMMANDS: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    steps:
      - uses: actions/checkout@v6.0.1
        # DONT use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-windows
          path: .

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          init-shell: bash cmd.exe
          cache-environment: true
          post-cleanup: 'all'

      - name: Configure C++ Tests (win_64)
        shell: cmd /C call {0}
        # Rapidcheck tests are currently disabled on Windows due to a linking issue we need to investigate.
        if: false # ${{ inputs.run_cpp_tests == true || github.event_name != 'workflow_dispatch' }}
        run: |
          REM Some `CMAKE_*` variables (in particular CMAKE_GENERATOR_{PLATFORM,TOOLSET}) are set by mamba / micromamba / conda
          REM when the environment is activated.
          REM See: https://github.com/conda-forge/vc-feedstock/blob/c6bb71096319ff21ac8b75f7d91183be914c3d6b/recipe/activate.bat#L87-L131
          REM The values which are chosen prevent Ninja to be used as a generator with MSVC.
          REM We override those values so that we can.
          set CMAKE_GENERATOR_PLATFORM=
          set CMAKE_GENERATOR_TOOLSET=
          cd cpp
          cmake --preset windows-cl-conda-release -DTEST=ON
        env:
          ARCTICDB_USING_CONDA: 1
          ARCTICDB_BUILD_CPP_TESTS: 1
          ARCTIC_CMAKE_PRESET: windows-cl-conda-release

      - name: Build C++ Tests (win_64)
        shell: cmd /C call {0}
        # Rapidcheck tests are currently disabled on Windows due to a linking issue we need to investigate.
        if: false # ${{ inputs.run_cpp_tests == true || github.event_name != 'workflow_dispatch' }}
        run: |
          REM Some `CMAKE_*` variables (in particular CMAKE_GENERATOR_{PLATFORM,TOOLSET}) are set by mamba / micromamba / conda
          REM when the environment is activated.
          REM See: https://github.com/conda-forge/vc-feedstock/blob/c6bb71096319ff21ac8b75f7d91183be914c3d6b/recipe/activate.bat#L87-L131
          REM The values which are chosen prevent Ninja to be used as a generator with MSVC.
          REM We override those values so that we can.
          set CMAKE_GENERATOR_PLATFORM=
          set CMAKE_GENERATOR_TOOLSET=
          cd cpp
          cmake --build --preset windows-cl-conda-release --target arcticdb_rapidcheck_tests -j ${{ steps.cpu-cores.outputs.count }}
          cmake --build --preset windows-cl-conda-release --target test_unit_arcticdb -j ${{ steps.cpu-cores.outputs.count }}
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Run C++ Tests (win_64)
        shell: cmd /C call {0}
        # Rapidcheck tests are currently disabled on Windows due to a linking issue we need to investigate.
        if: false # ${{ inputs.run_cpp_tests == true || github.event_name != 'workflow_dispatch' }}
        run: |
          cd cpp/out/windows-cl-conda-release-build/
          ctest --output-on-failure
        env:
          CTEST_OUTPUT_ON_FAILURE: 1
          ARCTICDB_USING_CONDA: 1
          ARCTICDB_BUILD_CPP_TESTS: 1
          ARCTIC_CMAKE_PRESET: windows-cl-conda-release

  python_tests_windows:
    name: Python Tests (win_64)
    if: |
      always() &&
      !cancelled()
    needs: [compile_windows]
    runs-on: windows-latest
    env:
      ACTIONS_ALLOW_UNSECURE_COMMANDS: true
      SCCACHE_GHA_VERSION: ${{vars.SCCACHE_GHA_VERSION || 1}}
    steps:
      - uses: actions/checkout@v6.0.1
        # DONT use recursive submodules checkout to simulate conda feedstock build
        # with:
        #   submodules: recursive

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-windows
          path: .

      - name: Configure sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        with:
          sccache-version: ${{vars.SCCACHE_GHA_VERSION || 1}}

      - name: Install Conda environment from environment-dev.yml
        uses: mamba-org/setup-micromamba@v2.0.6
        with:
          environment-file: environment-dev.yml
          init-shell: bash cmd.exe
          cache-environment: true
          post-cleanup: 'all'

      - name: Install ArcticDB from artifacts
        shell: cmd /C call {0}
        run: |
          REM Protocol buffers compilation require not using build isolation.
          REM We should always retry due to unstable nature of connections and environments
          REM This reuses the build artifacts from the compile_windows step and make ArcticDB available for testing.
          python -m pip install --no-build-isolation --no-deps --retries 3 --timeout 400 -v -e .
        env:
          ARCTICDB_USING_CONDA: 1

      - name: Install npm
        uses: actions/setup-node@v6.1.0
        with:
          node-version: '24'

      - name: Install azurite
        shell: bash -elo pipefail {0}
        run: |
          npm install -g azurite
          # Ensure npm global bin is in PATH for subsequent steps
          # On Windows, npm global installs go to %APPDATA%\npm which may not be in PATH
          npm_config_prefix=$(npm config get prefix)
          echo "npm prefix: $npm_config_prefix"
          # Add npm global bin to PATH (works for both Unix and Windows paths in bash)
          npm_bin_dir="$npm_config_prefix"
          if [[ "$RUNNER_OS" == "Windows" ]]; then
            # Convert Windows path to Unix-style for bash (C:\Users\... -> /c/Users/...)
            npm_bin_dir=$(echo "$npm_bin_dir" | sed 's|^\([A-Z]\):|/\1|' | tr '[:upper:]' '[:lower:]' | sed 's|\\|/|g')
          fi
          npm_bin_dir="${npm_bin_dir}/bin"
          echo "$npm_bin_dir" >> $GITHUB_PATH
          export PATH="$npm_bin_dir:$PATH"
          # Verify azurite is accessible
          echo "PATH includes: $npm_bin_dir"
          which azurite && echo "Azurite found: $(which azurite)" || echo "Warning: azurite not found in PATH"

      - name: Check no arcticdb file depend on tests package
        shell: bash -elo pipefail {0}
        run: |
          build_tooling/checks.sh

      - name: Set persistent storage variables
        # Should be executed for all persistent storages but not for LMDB
        if: ${{ inputs.persistent_storage != 'no' }}
        uses: ./.github/actions/set_persistent_storage_env_vars
        with:
          aws_access_key: "${{ secrets.AWS_S3_ACCESS_KEY }}"
          aws_secret_key: "${{ secrets.AWS_S3_SECRET_KEY }}"
          gcp_access_key: "${{ secrets.GCP_S3_ACCESS_KEY }}"
          gcp_secret_key: "${{ secrets.GCP_S3_SECRET_KEY }}"
          azure_container: "githubblob" # DEFAULT BUCKET FOR AZURE
          azure_connection_string: "${{ secrets.AZURE_CONNECTION_STRING }}"
          persistent_storage: ${{ inputs.persistent_storage || 'no' }}

      - name: Set ArcticDB Debug Logging
        if: ${{ inputs.run_enable_logging }}
        uses: ./.github/actions/enable_logging

      - name: Setup tmate session
        uses: mxschmitt/action-tmate@v3
        if: ${{ inputs.debug_enabled }}

      - name: Install pytest-repeat
        shell: bash -elo pipefail {0}
        run: |
          python -m pip --retries 3 --timeout 180 install pytest-repeat

      - name: Test with pytest
        shell: bash -elo pipefail {0}
        run: |
          echo "Run commandline: $COMMANDLINE"
          eval "$COMMANDLINE"
          export ARCTICDB_RAND_SEED=$RANDOM
          export ARCTICDB_WARN_ON_WRITING_EMPTY_DATAFRAME=0
          if [[ "$(echo "$ARCTICDB_PYTEST_ARGS" | xargs)" == *pytest* ]]; then
            command="python -m $ARCTICDB_PYTEST_ARGS"
            echo "Run custom pytest command: $command"
            eval "$command"
          else
            cd python
            # Skip LMDB tests on Windows because those tests fill the disk entirely and makes the test suite fail.
            python -m pytest --timeout=3600 -vv -s --tb=short -n logical --dist worksteal -m "not lmdb" tests $ARCTICDB_PYTEST_ARGS
          fi
        env:
          ARCTICDB_USING_CONDA: 1
          COMMANDLINE: ${{ inputs.run_commandline }}
          ARCTICDB_PYTEST_ARGS: ${{ inputs.run_custom_pytest_command }}
          NODE_OPTIONS: --openssl-legacy-provider
